"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞

–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
- Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (tail -f)
- –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤
- –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON/CSV
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
- –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
"""

import asyncio
import json
import csv
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from typing import List, Dict, Iterator, Callable, Optional, Any
from pathlib import Path
from collections import Counter, defaultdict
import time

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã
from log_analyzer import LogEntry, LogParser, LogAnalyzer


# ============================================================================
# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
# ============================================================================

class AsyncLogParser:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ I/O –æ–ø–µ—Ä–∞—Ü–∏–π
    - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
    - –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
    """
    
    def __init__(self, filepath: str):
        self.filepath = Path(filepath)
        self.parser = LogParser(str(filepath))
    
    async def parse_async(self) -> List[LogEntry]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ñ–∞–π–ª–∞
        
        Note:
            –ò—Å–ø–æ–ª—å–∑—É–µ—Ç run_in_executor –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
            –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è event loop.
        """
        loop = asyncio.get_event_loop()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤ executor
        entries = await loop.run_in_executor(
            None,  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç default executor
            self.parser.parse
        )
        
        return entries
    
    async def parse_stream_async(
        self,
        chunk_size: int = 1000
    ) -> Iterator[List[LogEntry]]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –±–∞—Ç—á–∞–º–∏.
        
        Args:
            chunk_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        
        Yields:
            –ë–∞—Ç—á–∏ LogEntry
        
        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤.
        """
        loop = asyncio.get_event_loop()
        
        chunk = []
        for entry in self.parser.parse_stream():
            chunk.append(entry)
            
            if len(chunk) >= chunk_size:
                # –î–∞–µ–º event loop –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥—Ä—É–≥–∏–µ –∑–∞–¥–∞—á–∏
                await asyncio.sleep(0)
                yield chunk
                chunk = []
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π –Ω–µ–ø–æ–ª–Ω—ã–π –±–∞—Ç—á
        if chunk:
            yield chunk


async def process_multiple_files(
    filepaths: List[str],
    progress_callback: Optional[Callable[[str, int], None]] = None
) -> Dict[str, List[LogEntry]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
    
    Args:
        filepaths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
        progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {filename: logs}
    
    Example:
        >>> files = ['log1.txt', 'log2.txt', 'log3.txt']
        >>> results = await process_multiple_files(files)
        >>> for filename, logs in results.items():
        ...     print(f"{filename}: {len(logs)} –∑–∞–ø–∏—Å–µ–π")
    """
    
    async def parse_with_progress(filepath: str) -> tuple[str, List[LogEntry]]:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª —Å –æ—Ç—á–µ—Ç–æ–º –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        parser = AsyncLogParser(filepath)
        logs = await parser.parse_async()
        
        if progress_callback:
            progress_callback(filepath, len(logs))
        
        return Path(filepath).name, logs
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    tasks = [parse_with_progress(fp) for fp in filepaths]
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output = {}
    for result in results:
        if isinstance(result, Exception):
            print(f"–û—à–∏–±–∫–∞: {result}")
        else:
            filename, logs = result
            output[filename] = logs
    
    return output


# ============================================================================
# Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
# ============================================================================

class LogMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ª–æ–≥-—Ñ–∞–π–ª–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–∫–∞–∫ tail -f).
    
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–∞–π–ª–µ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –ø–æ –º–µ—Ä–µ –ø–æ—è–≤–ª–µ–Ω–∏—è.
    """
    
    def __init__(
        self,
        filepath: str,
        callback: Callable[[LogEntry], None],
        poll_interval: float = 0.5
    ):
        """
        Args:
            filepath: –ü—É—Ç—å –∫ –ª–æ–≥-—Ñ–∞–π–ª—É
            callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
            poll_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞ (—Å–µ–∫—É–Ω–¥—ã)
        """
        self.filepath = Path(filepath)
        self.callback = callback
        self.poll_interval = poll_interval
        self.parser = LogParser(str(filepath))
        self.running = False
    
    async def start(self):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ñ–∞–π–ª–∞.
        
        –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–π–ª –Ω–∞ –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö.
        """
        self.running = True
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –∫–æ–Ω–µ—Ü
        with open(self.filepath, 'r', encoding='utf-8') as f:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
            f.seek(0, 2)  # SEEK_END
            
            print(f"üì° –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ {self.filepath}... (Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)")
            
            while self.running:
                # –ß–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                line = f.readline()
                
                if line:
                    # –ü–∞—Ä—Å–∏–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                    entry = self.parser.parse_line(line)
                    if entry:
                        self.callback(entry)
                else:
                    # –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∂–¥–µ–º
                    await asyncio.sleep(self.poll_interval)
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥."""
        self.running = False


# ============================================================================
# –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤
# ============================================================================

@dataclass
class AlertRule:
    """
    –ü—Ä–∞–≤–∏–ª–æ –¥–ª—è –∞–ª–µ—Ä—Ç–∞.
    
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Å–ª–æ–≤–∏–µ –∏ –¥–µ–π—Å—Ç–≤–∏–µ –ø—Ä–∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–∏.
    """
    name: str
    condition: Callable[[LogEntry], bool]
    action: Callable[[LogEntry], None]
    cooldown: float = 60.0  # –°–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∞–ª–µ—Ä—Ç–∞–º–∏
    last_triggered: Optional[float] = None
    
    def check(self, entry: LogEntry) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å–ª–æ–≤–∏–µ –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ.
        
        Returns:
            True –µ—Å–ª–∏ –∞–ª–µ—Ä—Ç —Å—Ä–∞–±–æ—Ç–∞–ª
        """
        if not self.condition(entry):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º cooldown
        now = time.time()
        if self.last_triggered:
            if now - self.last_triggered < self.cooldown:
                return False  # Cooldown –µ—â–µ –∞–∫—Ç–∏–≤–µ–Ω
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        self.action(entry)
        self.last_triggered = now
        return True


class AlertManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–∏—Å—Ç–µ–º—ã –∞–ª–µ—Ä—Ç–æ–≤.
    
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª–∞–º–∏ –∞–ª–µ—Ä—Ç–æ–≤ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏.
    """
    
    def __init__(self):
        self.rules: List[AlertRule] = []
        self.alert_history: List[Dict] = []
    
    def add_rule(self, rule: AlertRule):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª–æ –∞–ª–µ—Ä—Ç–∞."""
        self.rules.append(rule)
    
    def check_entry(self, entry: LogEntry):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–ø–∏—Å—å –ø—Ä–æ—Ç–∏–≤ –≤—Å–µ—Ö –ø—Ä–∞–≤–∏–ª."""
        for rule in self.rules:
            if rule.check(entry):
                self.alert_history.append({
                    'timestamp': datetime.now(),
                    'rule': rule.name,
                    'entry': asdict(entry)
                })
    
    def get_alert_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∞–ª–µ—Ä—Ç–∞–º."""
        rule_counts = Counter(alert['rule'] for alert in self.alert_history)
        
        return {
            'total_alerts': len(self.alert_history),
            'by_rule': dict(rule_counts),
            'recent_alerts': self.alert_history[-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10
        }


# ============================================================================
# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
# ============================================================================

class AdvancedLogFilter:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ª–æ–≥–æ–≤.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è, —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏.
    """
    
    def __init__(self, logs: List[LogEntry]):
        self.logs = logs
    
    def by_time_range(
        self,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> 'AdvancedLogFilter':
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É.
        
        Args:
            start_time: –ù–∞—á–∞–ª–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
            end_time: –ö–æ–Ω–µ—Ü –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
        """
        filtered = []
        
        for log in self.logs:
            if start_time and log.timestamp < start_time:
                continue
            if end_time and log.timestamp > end_time:
                continue
            filtered.append(log)
        
        return AdvancedLogFilter(filtered)
    
    def by_path_regex(self, pattern: str) -> 'AdvancedLogFilter':
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç URL –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–º—É –≤—ã—Ä–∞–∂–µ–Ω–∏—é."""
        import re
        regex = re.compile(pattern)
        
        filtered = [log for log in self.logs if regex.search(log.path)]
        return AdvancedLogFilter(filtered)
    
    def by_custom_condition(
        self,
        condition: Callable[[LogEntry], bool]
    ) -> 'AdvancedLogFilter':
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–º—É —É—Å–ª–æ–≤–∏—é.
        
        Example:
            >>> # –ë–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ IP
            >>> filter.by_custom_condition(
            ...     lambda log: log.ip == '127.0.0.1' and log.size > 10000
            ... )
        """
        filtered = [log for log in self.logs if condition(log)]
        return AdvancedLogFilter(filtered)
    
    def sample(self, n: int) -> 'AdvancedLogFilter':
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∏–∑ n —ç–ª–µ–º–µ–Ω—Ç–æ–≤."""
        import random
        
        if n >= len(self.logs):
            return self
        
        sampled = random.sample(self.logs, n)
        return AdvancedLogFilter(sampled)
    
    def get_logs(self) -> List[LogEntry]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏."""
        return self.logs
    
    def count(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π."""
        return len(self.logs)


# ============================================================================
# –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
# ============================================================================

class TimeSeriesAggregator:
    """
    –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º.
    
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤.
    """
    
    def __init__(self, logs: List[LogEntry]):
        self.logs = logs
    
    def aggregate_by_interval(
        self,
        interval: timedelta,
        metric: str = 'count'
    ) -> Dict[datetime, float]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º.
        
        Args:
            interval: –î–ª–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, timedelta(minutes=5))
            metric: –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ ('count', 'size', 'error_rate')
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {timestamp: value} –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        
        Example:
            >>> # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
            >>> agg = TimeSeriesAggregator(logs)
            >>> data = agg.aggregate_by_interval(timedelta(minutes=5), 'count')
        """
        if not self.logs:
            return {}
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
        min_time = min(log.timestamp for log in self.logs)
        max_time = max(log.timestamp for log in self.logs)
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        intervals = defaultdict(list)
        current = min_time
        
        while current <= max_time:
            intervals[current] = []
            current += interval
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–æ–≥–∏ –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
        for log in self.logs:
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            interval_start = min_time
            while interval_start + interval <= log.timestamp:
                interval_start += interval
            
            intervals[interval_start].append(log)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        result = {}
        
        for timestamp, logs_in_interval in intervals.items():
            if metric == 'count':
                result[timestamp] = len(logs_in_interval)
            elif metric == 'size':
                result[timestamp] = sum(log.size for log in logs_in_interval)
            elif metric == 'error_rate':
                if logs_in_interval:
                    errors = sum(1 for log in logs_in_interval if log.status >= 400)
                    result[timestamp] = (errors / len(logs_in_interval)) * 100
                else:
                    result[timestamp] = 0.0
        
        return result
    
    def get_hourly_stats(self) -> Dict[int, Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —á–∞—Å–∞–º (0-23).
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {hour: stats}
        """
        hourly_logs = defaultdict(list)
        
        for log in self.logs:
            hourly_logs[log.timestamp.hour].append(log)
        
        stats = {}
        for hour, logs in hourly_logs.items():
            analyzer = LogAnalyzer(logs)
            stats[hour] = {
                'count': len(logs),
                'total_bytes': analyzer.total_bytes(),
                'error_rate': analyzer.error_rate(),
                'top_urls': analyzer.top_urls(3)
            }
        
        return stats


# ============================================================================
# –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
# ============================================================================

class DataExporter:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç JSON, CSV, –∏ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã.
    """
    
    @staticmethod
    def to_json(
        data: Any,
        filepath: str,
        indent: int = 2,
        ensure_ascii: bool = False
    ) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ JSON.
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            filepath: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            indent: –û—Ç—Å—Ç—É–ø—ã –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            ensure_ascii: –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ã
        """
        
        def default_serializer(obj):
            """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤."""
            if isinstance(obj, datetime):
                return obj.isoformat()
            elif isinstance(obj, LogEntry):
                return asdict(obj)
            elif isinstance(obj, Counter):
                return dict(obj)
            raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(
                data,
                f,
                indent=indent,
                ensure_ascii=ensure_ascii,
                default=default_serializer
            )
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filepath}")
    
    @staticmethod
    def logs_to_csv(logs: List[LogEntry], filepath: str) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –≤ CSV.
        
        Args:
            logs: –°–ø–∏—Å–æ–∫ –ª–æ–≥–æ–≤
            filepath: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        if not logs:
            print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—è –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ª–æ–≥–∞
            fieldnames = logs[0].__dataclass_fields__.keys()
            
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for log in logs:
                row = asdict(log)
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º datetime
                if isinstance(row['timestamp'], datetime):
                    row['timestamp'] = row['timestamp'].isoformat()
                writer.writerow(row)
        
        print(f"‚úÖ {len(logs)} –∑–∞–ø–∏—Å–µ–π —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {filepath}")
    
    @staticmethod
    def stats_to_markdown(analyzer: LogAnalyzer, filepath: str) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ Markdown.
        
        Args:
            analyzer: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –¥–∞–Ω–Ω—ã–º–∏
            filepath: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        summary = analyzer.summary()
        
        md_content = f"""# –û—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ª–æ–≥–æ–≤

–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤**: {summary['total_requests']:,}
- **–ü–µ—Ä–µ–¥–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö**: {summary['total_bytes']:,} –±–∞–π—Ç
- **–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞**: {summary['average_response_size']:.2f} –±–∞–π—Ç
- **–ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫**: {summary['error_rate']}
- **–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö**: {summary['success_rate']}

## –°—Ç–∞—Ç—É—Å –∫–æ–¥—ã

| –ö–æ–¥ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ |
|-----|------------|
"""
        
        for status, count in sorted(summary['status_codes'].items()):
            md_content += f"| {status} | {count:,} |\n"
        
        md_content += "\n## –¢–æ–ø-5 URL\n\n| URL | –ó–∞–ø—Ä–æ—Å–æ–≤ |\n|-----|----------|\n"
        
        for url, count in summary['top_urls']:
            md_content += f"| {url} | {count:,} |\n"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filepath}")


# ============================================================================
# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# ============================================================================

async def demo_async_processing():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤."""
    print("\n" + "=" * 60)
    print("–ê–°–ò–ù–•–†–û–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï–°–ö–û–õ–¨–ö–ò–• –§–ê–ô–õ–û–í")
    print("=" * 60)
    
    # –î–ª—è –¥–µ–º–æ —Å–æ–∑–¥–∞–¥–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ø–∏–π sample_logs.txt
    import shutil
    
    files = []
    base_file = 'sample_logs.txt'
    
    if not Path(base_file).exists():
        print(f"‚ö†Ô∏è  –§–∞–π–ª {base_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ø–∏–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    for i in range(3):
        temp_file = f'temp_log_{i}.txt'
        shutil.copy(base_file, temp_file)
        files.append(temp_file)
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        def progress(filename, count):
            print(f"  ‚úÖ {filename}: {count} –∑–∞–ø–∏—Å–µ–π")
        
        results = await process_multiple_files(files, progress)
        
        print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")
        
        total_logs = sum(len(logs) for logs in results.values())
        print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_logs}")
    
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for f in files:
            Path(f).unlink(missing_ok=True)


def demo_alerts():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–ª–µ—Ä—Ç–æ–≤."""
    print("\n" + "=" * 60)
    print("–°–ò–°–¢–ï–ú–ê –ê–õ–ï–†–¢–û–í")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –∞–ª–µ—Ä—Ç–æ–≤
    alert_mgr = AlertManager()
    
    # –ü—Ä–∞–≤–∏–ª–æ 1: –û—à–∏–±–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞ (5xx)
    def server_error_action(entry: LogEntry):
        print(f"üö® –ê–õ–ï–†–¢: –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞! {entry.status} - {entry.path}")
    
    alert_mgr.add_rule(AlertRule(
        name="server_errors",
        condition=lambda e: e.status >= 500,
        action=server_error_action,
        cooldown=30.0
    ))
    
    # –ü—Ä–∞–≤–∏–ª–æ 2: –ë–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã
    def large_response_action(entry: LogEntry):
        print(f"‚ö†Ô∏è  –ê–õ–ï–†–¢: –ë–æ–ª—å—à–æ–π –æ—Ç–≤–µ—Ç! {entry.size} –±–∞–π—Ç –¥–ª—è {entry.path}")
    
    alert_mgr.add_rule(AlertRule(
        name="large_responses",
        condition=lambda e: e.size > 10000,
        action=large_response_action,
        cooldown=60.0
    ))
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ sample_logs.txt
    if Path('sample_logs.txt').exists():
        parser = LogParser('sample_logs.txt')
        logs = parser.parse()
        
        print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–∏—Å–µ–π...")
        for log in logs:
            alert_mgr.check_entry(log)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤
        stats = alert_mgr.get_alert_stats()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤:")
        print(f"  –í—Å–µ–≥–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ: {stats['total_alerts']}")
        print(f"  –ü–æ –ø—Ä–∞–≤–∏–ª–∞–º: {stats['by_rule']}")


def demo_advanced_filters():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤."""
    print("\n" + "=" * 60)
    print("–ü–†–û–î–í–ò–ù–£–¢–´–ï –§–ò–õ–¨–¢–†–´")
    print("=" * 60)
    
    if not Path('sample_logs.txt').exists():
        print("‚ö†Ô∏è  –§–∞–π–ª sample_logs.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    parser = LogParser('sample_logs.txt')
    logs = parser.parse()
    
    # –°–ª–æ–∂–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    print("\n1Ô∏è‚É£ –§–∏–ª—å—Ç—Ä: GET –∑–∞–ø—Ä–æ—Å—ã –∫ /api/* —Å –æ—à–∏–±–∫–∞–º–∏")
    filtered = (AdvancedLogFilter(logs)
                .by_path_regex(r'^/api/')
                .by_custom_condition(lambda e: e.method == 'GET')
                .by_custom_condition(lambda e: e.status >= 400))
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ: {filtered.count()} –∑–∞–ø–∏—Å–µ–π")
    for log in filtered.get_logs()[:5]:
        print(f"     {log.method} {log.path} - {log.status}")
    
    # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    if logs:
        print("\n2Ô∏è‚É£ –§–∏–ª—å—Ç—Ä: –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
        latest_time = max(log.timestamp for log in logs)
        hour_ago = latest_time - timedelta(hours=1)
        
        recent = AdvancedLogFilter(logs).by_time_range(start_time=hour_ago)
        print(f"   –ù–∞–π–¥–µ–Ω–æ: {recent.count()} –∑–∞–ø–∏—Å–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å")


def demo_time_series():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏."""
    print("\n" + "=" * 60)
    print("–ê–ù–ê–õ–ò–ó –í–†–ï–ú–ï–ù–ù–´–• –†–Ø–î–û–í")
    print("=" * 60)
    
    if not Path('sample_logs.txt').exists():
        print("‚ö†Ô∏è  –§–∞–π–ª sample_logs.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    parser = LogParser('sample_logs.txt')
    logs = parser.parse()
    
    aggregator = TimeSeriesAggregator(logs)
    
    # –ü–æ—á–∞—Å–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º:")
    hourly = aggregator.get_hourly_stats()
    
    for hour in sorted(hourly.keys()):
        stats = hourly[hour]
        print(f"\n  {hour:02d}:00")
        print(f"    –ó–∞–ø—Ä–æ—Å–æ–≤: {stats['count']}")
        print(f"    –î–∞–Ω–Ω—ã—Ö: {stats['total_bytes']} –±–∞–π—Ç")
        print(f"    –û—à–∏–±–æ–∫: {stats['error_rate']:.1f}%")


def demo_export():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö."""
    print("\n" + "=" * 60)
    print("–≠–ö–°–ü–û–†–¢ –î–ê–ù–ù–´–•")
    print("=" * 60)
    
    if not Path('sample_logs.txt').exists():
        print("‚ö†Ô∏è  –§–∞–π–ª sample_logs.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    parser = LogParser('sample_logs.txt')
    logs = parser.parse()
    analyzer = LogAnalyzer(logs)
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON
    print("\n1Ô∏è‚É£ –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ JSON")
    DataExporter.to_json(
        analyzer.summary(),
        'stats_export.json'
    )
    
    # –≠–∫—Å–ø–æ—Ä—Ç –ª–æ–≥–æ–≤ –≤ CSV
    print("\n2Ô∏è‚É£ –≠–∫—Å–ø–æ—Ä—Ç –ª–æ–≥–æ–≤ –≤ CSV")
    DataExporter.logs_to_csv(logs[:10], 'logs_export.csv')
    
    # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ Markdown
    print("\n3Ô∏è‚É£ –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ Markdown")
    DataExporter.stats_to_markdown(analyzer, 'report.md')


if __name__ == "__main__":
    print("=" * 60)
    print("–ü–†–û–î–í–ò–ù–£–¢–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ê–ù–ê–õ–ò–ó–ê –õ–û–ì–û–í")
    print("=" * 60)
    
    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –¥–µ–º–æ
    demo_alerts()
    demo_advanced_filters()
    demo_time_series()
    demo_export()
    
    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –¥–µ–º–æ
    print("\n" + "=" * 60)
    print("–ê–°–ò–ù–•–†–û–ù–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò")
    print("=" * 60)
    
    asyncio.run(demo_async_processing())
    
    print("\n" + "=" * 60)
    print("‚úÖ –í—Å–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print("=" * 60)
    
    print("\nüí° –î–ª—è real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
    print("   python log_monitor_demo.py")

